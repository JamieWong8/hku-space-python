# ğŸ—ï¸ Deal Scout - Technology Stack Overview

## Executive Summary

Deal Scout is a full-stack machine learning web application that evaluates startup investment opportunities using ensemble ML models, real-time data ingestion from Kaggle, and a modern responsive UI. The application provides instant-start performance with background model training and precomputed tier caching.

**Architecture:** Flask-based monolith with ML pipeline  
**Deployment:** Single-server with optional Docker containerization  
**Performance:** <3 second startup, 2-3 second analysis generation  
**Data Sources:** Kaggle (primary), Synthetic fallback  

---

## ğŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          USER INTERFACE LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   HTML5 +    â”‚  â”‚   Bootstrap  â”‚  â”‚  JavaScript  â”‚  â”‚   Chart.js  â”‚ â”‚
â”‚  â”‚   Jinja2     â”‚  â”‚    5.3.x     â”‚  â”‚    ES6+      â”‚  â”‚  (optional) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                  â”‚                  â”‚                â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                  â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         WEB FRAMEWORK LAYER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Flask 3.0+ (Python 3.9+)                       â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  â”œâ”€ Routes & API Endpoints (/api/companies, /analyze_company)   â”‚  â”‚
â”‚  â”‚  â”œâ”€ Template Rendering (Jinja2)                                 â”‚  â”‚
â”‚  â”‚  â”œâ”€ Session Management                                           â”‚  â”‚
â”‚  â”‚  â”œâ”€ Static File Serving (CSS, JS, Images)                       â”‚  â”‚
â”‚  â”‚  â””â”€ Error Handling & Admin Endpoints                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MACHINE LEARNING PIPELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Scikit-Learn Ensemble Models                    â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Classification (Success Prediction)                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ RandomForestClassifier (200-400 trees)                 â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ HistGradientBoostingClassifier                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ ExtraTreesClassifier                                   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ LogisticRegression (linear baseline)                   â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ VotingClassifier (soft voting ensemble)                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â†’ Best model selected by held-out accuracy               â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Regression (Funding & Valuation Prediction)              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ RandomForestRegressor (300 trees)                      â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ StandardScaler for feature normalization               â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Feature Engineering                                       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ 11 Numerical features (funding, team, market, etc.)    â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ 9 Categorical features (industry, location, round)     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ One-hot encoding for categoricals                      â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Log transforms for skewed distributions                â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Derived metrics (efficiency, per-employee ratios)      â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA LAYER                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Kaggle API      â”‚  â”‚  In-Memory Cache â”‚  â”‚  File System Cache â”‚    â”‚
â”‚  â”‚  (kagglehub)     â”‚  â”‚  (dictionaries)  â”‚  â”‚  (.pkl files)      â”‚    â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚                    â”‚    â”‚
â”‚  â”‚  â€¢ investments   â”‚  â”‚  â€¢ ANALYSIS_     â”‚  â”‚  â€¢ Model weights   â”‚    â”‚
â”‚  â”‚    _VC.csv       â”‚  â”‚    CACHE         â”‚  â”‚  â€¢ Precomputed     â”‚    â”‚
â”‚  â”‚  â€¢ 400 rows      â”‚  â”‚  â€¢ sample_data   â”‚  â”‚    tiers           â”‚    â”‚
â”‚  â”‚    (default)     â”‚  â”‚  â€¢ Tier filters  â”‚  â”‚  â€¢ Scaler state    â”‚    â”‚
â”‚  â”‚  â€¢ Fallback to   â”‚  â”‚                  â”‚  â”‚  â€¢ Feature columns â”‚    â”‚
â”‚  â”‚    synthetic     â”‚  â”‚                  â”‚  â”‚                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       VISUALIZATION LAYER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Matplotlib (Server-Side Rendering)                   â”‚  â”‚
â”‚  â”‚                                                                   â”‚  â”‚
â”‚  â”‚  â€¢ 6-Chart Analysis Dashboard (20x13 inches, 120 DPI)           â”‚  â”‚
â”‚  â”‚  â€¢ PNG generation with base64 encoding                           â”‚  â”‚
â”‚  â”‚  â€¢ Enhanced styling (shadows, gradients, borders)                â”‚  â”‚
â”‚  â”‚  â€¢ Dynamic color schemes per chart type                          â”‚  â”‚
â”‚  â”‚  â€¢ ~340KB output size                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DEPLOYMENT & INFRASTRUCTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Python     â”‚  â”‚   Virtual    â”‚  â”‚   Docker     â”‚  â”‚   Gunicorn  â”‚ â”‚
â”‚  â”‚   3.9-3.11   â”‚  â”‚   Env (venv) â”‚  â”‚  (optional)  â”‚  â”‚  (optional) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚  â”‚  PowerShell  â”‚  â”‚   Windows    â”‚                                     â”‚
â”‚  â”‚  Bootstrap   â”‚  â”‚   Optimized  â”‚                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Frontend Technology Stack

### 1. HTML5 + Jinja2 Templates
**Purpose:** Server-side template rendering  
**Why Chosen:** Seamless integration with Flask, dynamic content generation

**Key Features:**
- **Template Inheritance:** Base template with blocks for reusable layouts
- **Dynamic Content:** Server-side data binding for company information
- **SEO-Friendly:** Fully rendered HTML on server
- **Accessibility:** Semantic HTML5 elements, ARIA labels

**Files:**
- `templates/index.html` (1825 lines) - Main application UI
- `templates/error.html` - Error page template

---

### 2. Bootstrap 5.3.x
**Purpose:** Responsive UI framework and component library  
**Why Chosen:** Industry-standard, mobile-first, extensive component library

**Key Features:**
- **Grid System:** 12-column responsive layout
- **Components:** Cards, modals, tabs, badges, buttons
- **Utilities:** Spacing, colors, typography, flexbox
- **Dark Mode:** Built-in theme support with `data-theme` attribute

**Components Used:**
- **Cards:** Company displays, analysis panels
- **Modals:** Full-screen company analysis viewer
- **Tabs:** Multi-tab analysis interface (Overview, Benchmarks, Fundamentals, Risk Analysis, Commentary)
- **Badges:** Tier indicators (Invest/Monitor/Avoid), risk severity
- **Forms:** Search, filters, company evaluation inputs

---

### 3. Custom CSS (4 files)
**Purpose:** Branded styling, dark mode, custom components  
**Why Chosen:** Fine-grained control over appearance

**Files:**
1. **`dashboard.css`** (460+ lines)
   - Chart cards, panel styling
   - Dark mode overrides
   - Table enhancements
   - Analysis tab styling

2. **`components.css`** (700+ lines)
   - Tier badges (Invest/Monitor/Avoid)
   - Dark mode toggle button
   - Glass morphism effects
   - Neomorphic designs
   - Card variations

3. **`evaluate.css`** (340+ lines)
   - Company evaluation forms
   - Input field styling
   - Responsive layouts

4. **`styles.css`** (base styles)
   - CSS custom properties (variables)
   - Global typography
   - Color schemes

**Design System:**
```css
/* CSS Variables */
--color-primary: #4f46e5;        /* Indigo */
--color-success: #10b981;        /* Green */
--color-warning: #f59e0b;        /* Amber */
--color-danger: #ef4444;         /* Red */

--surface-base: #1e293b;         /* Dark mode base */
--surface-raised: #334155;       /* Dark mode elevated */
--text-primary: #f1f5f9;         /* Dark mode text */
```

---

### 4. JavaScript (Vanilla ES6+)
**Purpose:** Client-side interactivity, AJAX, dynamic updates  
**Why Chosen:** No framework overhead, native browser support, fast execution

**Key Features:**
- **AJAX Calls:** Fetch API for `/api/companies`, `/analyze_company`
- **Dynamic Filtering:** Real-time tier, industry, location filtering
- **Modal Management:** Full-screen analysis viewer
- **Tab Switching:** Multi-tab navigation
- **Theme Toggle:** Dark/light mode switching with localStorage
- **Search:** Debounced company name search
- **Responsive Charts:** Base64 image rendering

**Core Functions:**
```javascript
// Company search with debouncing
function searchCompanies(query)

// Filter by investment tier
function filterByTier(tier)

// Display company analysis modal
function displayCompanyAnalysis(analysis)

// Toggle dark/light mode
function toggleTheme()

// Tab navigation
function switchTab(tabName)
```

**Files:**
- Embedded in `templates/index.html` (~500 lines of JS)
- Modular function organization
- Event-driven architecture

---

### 5. Font Awesome 6.4.0
**Purpose:** Icon library  
**Why Chosen:** Comprehensive icon set, easy integration

**Icons Used:**
- ğŸ” Search, filter icons
- ğŸ“Š Chart, analytics icons
- âš ï¸ Warning, risk icons
- ğŸ’¼ Business, industry icons
- ğŸŒ™ Dark mode toggle
- âœ… Success indicators

---

### 6. Matplotlib (Server-Side Visualization)
**Purpose:** Generate static chart images on server  
**Why Chosen:** Python-native, publication-quality, highly customizable

**Charts Generated:**
1. **Gauge Chart:** Attractiveness score (0-100)
2. **Bar Chart:** Success probability benchmarking
3. **Donut Chart:** Success factor distribution
4. **Horizontal Bar:** Industry comparison
5. **Scatter Plot:** Risk-return matrix
6. **Radar Chart:** Business fundamentals

**Output:**
- Format: PNG (base64 encoded)
- Resolution: 120 DPI
- Size: 20x13 inches (2400x1560 pixels)
- File size: ~340KB
- Delivered via: `<img src="data:image/png;base64,...">`

**Why Server-Side Instead of Client-Side?**
- Complex calculations require Python ML models
- Consistent rendering across all browsers
- No JavaScript library dependency
- Can leverage NumPy, Pandas for data processing

---

## ğŸ”§ Backend Technology Stack

### 1. Flask 3.0+
**Purpose:** Web framework and application server  
**Why Chosen:** Lightweight, flexible, Python-native, extensive ecosystem

**Architecture:**
- **Routing:** RESTful API endpoints + page rendering
- **Templates:** Jinja2 integration
- **Sessions:** Server-side session management
- **Static Files:** CSS, JS, image serving
- **Error Handling:** Custom error pages, logging

**Key Routes:**
```python
@app.route('/')                          # Home page
@app.route('/api/companies')             # Company catalog API
@app.route('/analyze_company/<name>')   # Company analysis API
@app.route('/evaluate')                  # Manual evaluation page
@app.route('/admin/*')                   # Admin diagnostics
```

**Configuration:**
```python
app.config['SECRET_KEY']           # Session encryption
app.config['JSON_SORT_KEYS']       # API response formatting
app.config['TEMPLATES_AUTO_RELOAD'] # Dev hot reload
```

---

### 2. Python 3.9-3.11
**Purpose:** Core programming language  
**Why Chosen:** ML ecosystem, readability, rapid development

**Key Libraries Used:**

| Library | Version | Purpose |
|---------|---------|---------|
| Flask | 3.0+ | Web framework |
| scikit-learn | 1.3+ | Machine learning |
| pandas | 2.0+ | Data manipulation |
| numpy | 1.24+ | Numerical computing |
| matplotlib | 3.7+ | Visualization |
| kagglehub | 0.1+ | Kaggle data download |
| joblib | 1.3+ | Model serialization |

---

### 3. Scikit-Learn ML Pipeline
**Purpose:** Machine learning models and training  
**Why Chosen:** Industry-standard, well-documented, comprehensive algorithms

#### Classification Models (Success Prediction)

**1. RandomForestClassifier**
```python
RandomForestClassifier(
    n_estimators=200-400,      # 200-400 decision trees
    max_depth=None,            # No depth limit (prevents underfitting)
    min_samples_leaf=1-2,      # Minimum samples at leaf nodes
    max_features='sqrt',       # Feature sampling strategy
    class_weight='balanced_subsample',  # Handle class imbalance
    random_state=42,
    n_jobs=-1                  # Parallel processing
)
```
**How It Works:**
- Ensemble of decision trees voting on classification
- Each tree trained on random subset of data (bagging)
- Reduces variance, handles non-linear relationships
- Typical accuracy: 75-85%

**2. HistGradientBoostingClassifier**
```python
HistGradientBoostingClassifier(
    learning_rate=0.05-0.1,    # Step size shrinkage
    max_iter=100-300,          # Number of boosting iterations
    max_depth=8-12,            # Tree depth
    min_samples_leaf=10-30,    # Regularization
    l2_regularization=0-0.1    # Ridge penalty
)
```
**How It Works:**
- Sequential tree building (boosting)
- Each tree corrects errors of previous trees
- Histogram-based for speed on large datasets
- Often best performer on tabular data

**3. ExtraTreesClassifier**
```python
ExtraTreesClassifier(
    n_estimators=200-400,
    max_depth=None,
    min_samples_split=2-5,
    max_features='sqrt'
)
```
**How It Works:**
- Similar to Random Forest but more randomized
- Splits chosen randomly instead of optimally
- Reduces variance further, faster training
- Good for high-dimensional data

**4. LogisticRegression**
```python
LogisticRegression(
    C=0.1-10.0,               # Inverse regularization strength
    penalty='l2',             # Ridge regularization
    solver='lbfgs',           # Optimization algorithm
    max_iter=1000,
    class_weight='balanced'
)
```
**How It Works:**
- Linear model with sigmoid activation
- Strong baseline for comparison
- Interpretable coefficients
- Fast training and prediction

**5. VotingClassifier (Soft Ensemble)**
```python
VotingClassifier(
    estimators=[
        ('rf', RandomForestClassifier),
        ('hgb', HistGradientBoostingClassifier),
        ('etc', ExtraTreesClassifier),
        ('lr', LogisticRegression)
    ],
    voting='soft'             # Use probability estimates
)
```
**How It Works:**
- Combines predictions from all base models
- Averages probability estimates
- Often achieves best overall accuracy
- Reduces individual model biases

**Model Selection Strategy:**
- All 5 models trained with GridSearchCV hyperparameter tuning
- Evaluated on held-out test set (20% of data)
- Best model selected by accuracy score
- Threshold tuning applied for optimal precision-recall balance

---

#### Regression Models (Funding & Valuation)

**RandomForestRegressor**
```python
RandomForestRegressor(
    n_estimators=300,
    max_depth=None,
    min_samples_split=4,
    min_samples_leaf=2,
    max_features='sqrt',
    random_state=42,
    n_jobs=-1
)
```
**Purpose:**
- Predict funding amounts (continuous target)
- Predict company valuations
- RÂ² scores typically 80-85%

**How It Works:**
- Ensemble of regression trees
- Averages predictions across trees
- Handles non-linear relationships
- Robust to outliers

---

#### Feature Engineering

**Numerical Features (11):**
1. `funding_amount_usd` - Total funding raised
2. `valuation_usd` - Company valuation
3. `team_size` - Number of employees
4. `years_since_founding` - Company age
5. `num_investors` - Investor count
6. `competition_level` - Market competition (1-10)
7. `market_size_billion_usd` - Total addressable market
8. `funding_efficiency` - Valuation / Funding ratio
9. `funding_per_employee` - Funding / Team size
10. `funding_amount_log` - Log-transformed funding
11. `valuation_log` - Log-transformed valuation

**Categorical Features (9):**
1. `industry` - Tech sector (12 categories)
2. `industry_group` - Consolidated industry (13 categories)
3. `location` - Country/city
4. `region` - Geographic region (8 regions)
5. `funding_round` - Investment stage (Seed, A, B, C, D+)
6. `status` - Operating, Acquired, IPO, Closed
7. `age_category` - Startup, Early, Growth, Mature, Established
8. `team_size_category` - Small, Medium, Large, Very Large, Enterprise
9. `competition_category` - Low, Medium, High, Very High

**Encoding:**
- One-hot encoding for all categorical features
- StandardScaler normalization for numerical features
- Feature vector size: ~50-100 dimensions (varies by dataset)

---

#### Scoring Methodology

**Attractiveness Score (0-100):**
```python
def calculate_attractiveness_score(
    success_probability,      # From ML classifier (0-1)
    market_size,             # TAM in billions
    competition_level,       # 1-10 scale
    team_size,              # Number of employees
    num_investors           # Investor count
):
    # Weighted combination
    score = (
        success_probability * 70.0 +           # 70% weight
        normalize_market(market_size, competition) * 15.0 +  # 15% weight
        normalize_team(team_size) * 10.0 +     # 10% weight
        normalize_investors(num_investors) * 5.0  # 5% weight
    )
    
    # Hard gating for quality
    if success_probability < 0.40:
        score = min(score, 49)  # Cap at Avoid tier
    elif success_probability < 0.50:
        score = min(score, 64)  # Cap at Monitor tier
    
    return score
```

**Investment Tiers:**
- **Invest:** Score â‰¥ 65 (High conviction)
- **Monitor:** Score 50-64 (Watch list)
- **Avoid:** Score < 50 (Pass)

**Success Rate Calibration:**
```python
SUCCESS_RATE_CONFIG = {
    'target_success_rate': 0.25,        # 25% overall target
    'operating_base_rate': 0.28,        # Base rate for active companies
    'acquired_ipo_rate': 1.0,           # 100% for successful exits
    'closed_success_rate': 0.05,        # 5% for closed companies
    'funding_boost_threshold': 2000000, # $2M+ gets boost
}
```

---

### 4. Pandas Data Processing
**Purpose:** Data manipulation, cleaning, transformation  
**Why Chosen:** Industry-standard, powerful API, integrates with scikit-learn

**Key Operations:**
- **CSV Loading:** Read Kaggle datasets
- **Data Cleaning:** Handle missing values, type conversion
- **Feature Engineering:** Create derived columns
- **Filtering:** Industry, region, tier filtering
- **Aggregation:** Industry benchmarks, statistics
- **Merging:** Combine multiple datasets

**Performance:**
- In-memory DataFrames for speed
- Vectorized operations (avoid loops)
- Default 400-row limit for fast startup
- Can scale to 10,000+ rows

---

### 5. NumPy Numerical Computing
**Purpose:** Array operations, mathematical functions  
**Why Chosen:** Foundation for pandas/scikit-learn, C-speed performance

**Usage:**
- Feature scaling and normalization
- Logarithmic transforms
- Statistical calculations
- Matrix operations for ML
- Chart coordinate generation

---

### 6. KaggleHub Data Integration
**Purpose:** Download real startup datasets from Kaggle  
**Why Chosen:** Access to real-world VC investment data

**Dataset:**
- **Source:** `afnanurrahim/investment-startup-funding-deals`
- **File:** `investments_VC.csv`
- **Size:** 400 rows (default), up to 10,000+ available
- **Fields:** 30+ columns (company name, funding, investors, status, etc.)

**Data Flow:**
```python
def download_kaggle_startup_data():
    # 1. Try local cache first
    if os.path.exists('kaggle_data/investments_VC.csv'):
        return load_local_cache()
    
    # 2. Download from Kaggle with timeout
    try:
        path = kagglehub.dataset_download('afnanurrahim/...')
        df = pd.read_csv(path)
        return process_data(df)
    except Exception:
        # 3. Fallback to synthetic data
        return generate_synthetic_data()
```

**Fallback Strategy:**
- Primary: Kaggle API with credentials
- Secondary: Cached CSV file
- Tertiary: Synthetic data generation (1000 samples)

---

### 7. Caching Strategy

**Three-Level Caching:**

**Level 1: In-Memory Cache**
```python
ANALYSIS_CACHE = {}        # Company analysis results
sample_data = DataFrame    # Loaded dataset
precomputed_tiers = []     # Tier assignments
```
- Fastest access (milliseconds)
- Lost on restart
- Used for active session

**Level 2: File System Cache**
```python
.model_cache/
â”œâ”€â”€ meta.json                    # Cache metadata
â”œâ”€â”€ classifier_<sig>.pkl         # Trained classifier
â”œâ”€â”€ regressor_<sig>.pkl          # Trained regressor
â”œâ”€â”€ scaler_<sig>.pkl             # Feature scaler
â”œâ”€â”€ precompute_<sig>.pkl         # Precomputed tiers
â””â”€â”€ analysis_cache_<sig>.pkl     # Analysis results
```
- Persists across restarts
- Invalidated by data signature changes
- Loaded on startup (instant-start)

**Level 3: Background Training**
```python
def kickoff_background_training():
    thread = threading.Thread(target=train_models)
    thread.daemon = True
    thread.start()
```
- Models train in background thread
- Updates cache when complete
- Doesn't block startup

**Cache Invalidation:**
```python
SCORING_SCHEMA_VERSION = '2025-10-01-stricter-tiers'

def _compute_data_signature(df):
    return hashlib.md5(
        f"{len(df)}|{len(df.columns)}|{df['funding'].sum()}"
    ).hexdigest()
```
- Schema version bump invalidates all caches
- Data signature detects dataset changes
- Force retrain with environment variable

---

### 8. PowerShell Bootstrap Script
**Purpose:** One-command application startup  
**Why Chosen:** Windows-native, automates environment setup

**`run_web_app.ps1` Features:**
```powershell
# Virtual environment creation
python -m venv venv

# Dependency installation
pip install -r requirements.txt

# Environment variable configuration
$env:KAGGLE_MAX_ROWS = "400"
$env:FLASK_ENV = "development"
$env:BOOTSTRAP_FAST = "true"

# Flask server launch
python app.py
```

**Optimizations:**
- Checks for Python installation
- Creates venv if missing
- Installs/updates dependencies
- Sets performance flags
- Handles Kaggle credentials
- Launches with auto-reload

---

## ğŸ¤– Machine Learning Methodology

### Training Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: DATA LOADING                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Try Kaggle API (kagglehub)                               â”‚
â”‚ 2. Fallback to local cache (kaggle_data/investments_VC.csv) â”‚
â”‚ 3. Generate synthetic data if all fail                      â”‚
â”‚ Output: Raw DataFrame (400-10000 rows)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: DATA CLEANING & PREPROCESSING                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Parse funding amounts (handle $, M, B, K formats)         â”‚
â”‚ â€¢ Handle missing values (forward fill, median imputation)   â”‚
â”‚ â€¢ Consolidate industries (12 categories)                    â”‚
â”‚ â€¢ Map locations to regions (8 regions)                      â”‚
â”‚ â€¢ Create success labels (acquired/IPO = 1, else = 0)        â”‚
â”‚ â€¢ Apply success rate calibration (25% target)               â”‚
â”‚ Output: Clean DataFrame with labels                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: FEATURE ENGINEERING                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Numerical (11):                                             â”‚
â”‚ â€¢ Raw: funding, valuation, team, age, investors, etc.      â”‚
â”‚ â€¢ Derived: efficiency ratios, per-employee metrics          â”‚
â”‚ â€¢ Transforms: log(funding), log(valuation)                  â”‚
â”‚                                                             â”‚
â”‚ Categorical (9):                                            â”‚
â”‚ â€¢ One-hot encode: industry, location, round, status        â”‚
â”‚ â€¢ Binned: age category, team size category                 â”‚
â”‚                                                             â”‚
â”‚ Output: Feature matrix X (~50-100 columns)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: TRAIN-TEST SPLIT                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ 80% training, 20% testing                                 â”‚
â”‚ â€¢ Stratified split for classification (balanced classes)    â”‚
â”‚ â€¢ Random state = 42 for reproducibility                     â”‚
â”‚ Output: X_train, X_test, y_train, y_test                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: HYPERPARAMETER TUNING (GridSearchCV)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ For each model (RF, HGB, ETC, LR):                         â”‚
â”‚ â€¢ Define parameter grid                                     â”‚
â”‚ â€¢ 3-fold cross-validation on training set                  â”‚
â”‚ â€¢ Optimize for accuracy                                     â”‚
â”‚ â€¢ Select best hyperparameters                              â”‚
â”‚ Output: 5 tuned models (including voting ensemble)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: MODEL EVALUATION & SELECTION                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Test all 5 models on held-out test set                   â”‚
â”‚ â€¢ Calculate accuracy scores                                 â”‚
â”‚ â€¢ Select best performer                                     â”‚
â”‚ â€¢ Typical accuracy: 75-85%                                  â”‚
â”‚ Output: Best classifier                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: THRESHOLD TUNING (Optional)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Try thresholds from 0.3 to 0.7 (step 0.05)              â”‚
â”‚ â€¢ Find threshold maximizing accuracy                        â”‚
â”‚ â€¢ Wrap classifier in ThresholdedClassifier                 â”‚
â”‚ Output: Tuned classifier with optimal threshold            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: REGRESSION MODEL TRAINING                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Train RandomForestRegressor for funding prediction        â”‚
â”‚ â€¢ Train RandomForestRegressor for valuation prediction      â”‚
â”‚ â€¢ Typical RÂ² scores: 80-85%                                 â”‚
â”‚ Output: 2 regression models                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 9: MODEL PERSISTENCE & CACHING                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Save models to .model_cache/ (joblib)                    â”‚
â”‚ â€¢ Save scaler and feature metadata                          â”‚
â”‚ â€¢ Compute data signature for cache validation              â”‚
â”‚ Output: Cached models ready for inference                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 10: PRECOMPUTE INVESTMENT TIERS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Run analysis on all companies                             â”‚
â”‚ â€¢ Calculate attractiveness scores                           â”‚
â”‚ â€¢ Assign tiers (Invest/Monitor/Avoid)                      â”‚
â”‚ â€¢ Cache results for instant filtering                       â”‚
â”‚ Output: Precomputed tier column in sample_data             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Inference Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER REQUEST: Analyze "Company X"                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: CHECK ANALYSIS CACHE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if company_id in ANALYSIS_CACHE:                            â”‚
â”‚     return cached_result  # Instant response                â”‚
â”‚ else:                                                       â”‚
â”‚     continue to analysis                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: PREPARE FEATURES                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Extract company data (funding, team, industry, etc.)      â”‚
â”‚ â€¢ Engineer same features as training                        â”‚
â”‚ â€¢ One-hot encode categoricals                              â”‚
â”‚ â€¢ Align columns with training feature set                  â”‚
â”‚ â€¢ Scale numerical features with saved scaler               â”‚
â”‚ Output: Feature vector X (1 row, ~50-100 columns)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: ML PREDICTIONS                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Classification: success_probability = classifier.         â”‚
â”‚   predict_proba(X)[0][1]                                   â”‚
â”‚ â€¢ Regression 1: predicted_funding = funding_regressor.      â”‚
â”‚   predict(X)[0]                                            â”‚
â”‚ â€¢ Regression 2: predicted_valuation = valuation_regressor.  â”‚
â”‚   predict(X)[0]                                            â”‚
â”‚ Output: Raw ML predictions                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: PROBABILITY TEMPERING                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Apply shrinkage: p' = 0.7 * p + 0.3 * base_rate          â”‚
â”‚ â€¢ Enforces realistic success rates (not overconfident)      â”‚
â”‚ Output: Tempered probability                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: CALCULATE ATTRACTIVENESS SCORE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ score = (                                                   â”‚
â”‚     success_probability * 70 +                              â”‚
â”‚     normalize_market(market_size, competition) * 15 +       â”‚
â”‚     normalize_team(team_size) * 10 +                        â”‚
â”‚     normalize_investors(num_investors) * 5                  â”‚
â”‚ )                                                           â”‚
â”‚                                                             â”‚
â”‚ â€¢ Apply hard gating (cap score if low probability)          â”‚
â”‚ Output: Attractiveness score (0-100)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: ASSIGN INVESTMENT TIER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if score >= 65: tier = "Invest"                            â”‚
â”‚ elif score >= 50: tier = "Monitor"                         â”‚
â”‚ else: tier = "Avoid"                                        â”‚
â”‚ Output: Investment recommendation                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: GENERATE INSIGHTS & COMMENTARY                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Rule-based insights (funding vs. industry avg, etc.)      â”‚
â”‚ â€¢ Risk factor identification (competition, valuation)       â”‚
â”‚ â€¢ Strength/weakness analysis                                â”‚
â”‚ â€¢ AI-generated investment commentary                        â”‚
â”‚ Output: Text insights list                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: CREATE ANALYSIS DASHBOARD                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Generate 6 matplotlib charts                              â”‚
â”‚ â€¢ Apply enhanced styling (shadows, gradients, borders)      â”‚
â”‚ â€¢ Encode as base64 PNG                                      â”‚
â”‚ â€¢ ~2-3 seconds to generate                                  â”‚
â”‚ Output: Base64 image string (~340KB)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 9: CACHE RESULT                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ANALYSIS_CACHE[company_id] = full_analysis                  â”‚
â”‚ â€¢ Subsequent requests instant (no ML recomputation)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 10: RETURN JSON RESPONSE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ {                                                           â”‚
â”‚   "company_name": "Company X",                              â”‚
â”‚   "attractiveness_score": 72.4,                             â”‚
â”‚   "success_probability": 0.68,                              â”‚
â”‚   "investment_recommendation": "Invest",                    â”‚
â”‚   "risk_level": "Medium",                                   â”‚
â”‚   "insights": [...],                                        â”‚
â”‚   "risk_factors": [...],                                    â”‚
â”‚   "commentary": [...],                                      â”‚
â”‚   "dashboard_image": "data:image/png;base64,..."            â”‚
â”‚ }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Performance Optimizations

### 1. Instant-Start Bootstrap
**Problem:** Full model training takes 30-60 seconds  
**Solution:** Fast bootstrap with background training

```python
# On import (instant)
_fast_bootstrap_models(n_samples=300)  # ~2 seconds
kickoff_background_training()          # Async

# Bootstrap uses subset of data for quick models
# Background thread trains full models and updates cache
```

**Result:**
- Server starts in <3 seconds
- Initial requests work immediately (slightly lower accuracy)
- Full models ready within 30 seconds
- Models persist across restarts (cache)

---

### 2. Tier Precomputation
**Problem:** Filtering by tier requires analyzing all companies  
**Solution:** Precompute tiers at startup

```python
def precompute_investment_tiers():
    for company in sample_data:
        analysis = analyze_company(company)
        company['tier'] = analysis['recommendation']
        company['attractiveness_score'] = analysis['score']
    
    save_to_cache()
```

**Result:**
- Tier filtering is instant (DataFrame column filter)
- No ML computation on filter change
- Persisted to cache for next startup

---

### 3. Three-Level Caching
**Level 1:** In-memory (ANALYSIS_CACHE) - milliseconds  
**Level 2:** File system (.pkl files) - 100-200ms  
**Level 3:** Background training - seconds  

**Cache Hit Rates:**
- Company analysis: ~90% (users re-view companies)
- Model loading: ~95% (same data = same models)
- Tier filtering: 100% (precomputed)

---

### 4. Lazy Loading
**What's Lazy:**
- Kaggle credential check (only when needed)
- Full model training (background thread)
- Chart generation (only for viewed companies)

**What's Eager:**
- Data loading (needed for catalog)
- Bootstrap models (needed for analysis)
- Tier precomputation (needed for filters)

---

### 5. Data Limiting
**Default:** 400 rows from Kaggle dataset  
**Why:** 5x faster loading than full dataset (2000+ rows)  
**Configurable:** `KAGGLE_MAX_ROWS` environment variable

**Performance Impact:**
- 400 rows: 2-3 second load, 5 second training
- 2000 rows: 8-10 second load, 20 second training
- 10000 rows: 30-40 second load, 60+ second training

**Accuracy Impact:**
- Minimal (ensemble models generalize well)
- 400 rows sufficient for 75-80% accuracy
- Diminishing returns beyond 2000 rows

---

## ğŸ“¦ Deployment Options

### Option 1: Development Server (Default)
```powershell
.\run_web_app.ps1
```
- Flask built-in server
- Auto-reload on file changes
- Single-threaded
- Suitable for: Development, testing, demos

---

### Option 2: Production Server (Gunicorn)
```bash
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```
- Multi-process workers
- Better performance under load
- Production-ready
- Suitable for: Deployment, staging

---

### Option 3: Docker Container
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "app:app"]
```
- Containerized deployment
- Consistent environment
- Easy scaling
- Suitable for: Cloud deployment, Kubernetes

---

## ğŸ”’ Security Considerations

### 1. Kaggle Credentials
- **Storage:** `kaggle.json` (gitignored)
- **Permissions:** Read-only access to datasets
- **Fallback:** App works without credentials (synthetic data)

### 2. Flask Secret Key
- **Purpose:** Session encryption
- **Storage:** Environment variable or config file
- **Best Practice:** Generate with `secrets.token_hex(16)`

### 3. Input Validation
- **API Inputs:** Validated and sanitized
- **File Uploads:** Not implemented (safer)
- **SQL Injection:** N/A (no database)

### 4. CORS & CSRF
- **CORS:** Not enabled (same-origin only)
- **CSRF:** Not implemented (read-heavy application)
- **Recommendation:** Add for production if exposing API

---

## ğŸ“Š Performance Benchmarks

| Metric | Value | Notes |
|--------|-------|-------|
| **Startup Time** | 2-3 seconds | With bootstrap + cache |
| **Full Training** | 30-60 seconds | Background thread |
| **Company Analysis** | 50-100ms | With cache |
| **Chart Generation** | 2-3 seconds | First time |
| **Tier Filtering** | <10ms | Precomputed |
| **Search** | <50ms | In-memory filter |
| **Model Accuracy** | 75-85% | Classification |
| **Regression RÂ²** | 80-85% | Funding/valuation |
| **Cache Hit Rate** | 90%+ | Analysis requests |
| **Memory Usage** | 200-400MB | With 400 rows |
| **Disk Space** | 50MB | Cache + models |

---

## ğŸ¯ Design Principles

### 1. Instant Gratification
- Fast startup (<3 seconds)
- Immediate first analysis
- Progressive enhancement (background training)

### 2. Graceful Degradation
- Works without Kaggle credentials
- Works without internet (synthetic data)
- Works with minimal resources (bootstrap models)

### 3. Progressive Disclosure
- Simple catalog view initially
- Detailed analysis on demand
- Multi-tab exploration (optional)

### 4. Caching Everywhere
- In-memory cache for speed
- File system cache for persistence
- Precomputation for instant filters

### 5. Responsive Design
- Mobile-friendly (Bootstrap grid)
- Dark mode support
- Accessible (ARIA labels)

---

## ğŸ”® Future Enhancements

### Short Term
- [ ] User authentication
- [ ] Saved company lists
- [ ] Comparison mode (2 companies side-by-side)
- [ ] Export to PDF/CSV

### Medium Term
- [ ] Real-time data updates (webhook)
- [ ] Custom scoring weights
- [ ] Portfolio tracking
- [ ] Email alerts for tier changes

### Long Term
- [ ] PostgreSQL database (replace in-memory)
- [ ] Redis caching layer
- [ ] Celery for async tasks
- [ ] React frontend (SPA)
- [ ] GraphQL API
- [ ] Multi-user collaboration

---

## ğŸ“š Additional Resources

- **Main README:** [README.md](README.md)
- **Quick Start:** [QUICK_START_GUIDE.md](QUICK_START_GUIDE.md)
- **Scoring Methodology:** [SCORING_METHODOLOGY.md](SCORING_METHODOLOGY.md)
- **Visualization Docs:** [VISUALIZATION_ENHANCEMENTS.md](VISUALIZATION_ENHANCEMENTS.md)
- **Dark Mode Fix:** [DARK_MODE_FIX.md](DARK_MODE_FIX.md)

---

## ğŸ Conclusion

Deal Scout's tech stack is designed for:
- âœ… **Speed:** Instant startup, fast analysis
- âœ… **Reliability:** Graceful degradation, caching
- âœ… **Accuracy:** Ensemble ML models, rigorous validation
- âœ… **Usability:** Responsive UI, dark mode, intuitive navigation
- âœ… **Maintainability:** Modular code, comprehensive docs
- âœ… **Scalability:** Can handle 10,000+ companies

The combination of Flask's simplicity, scikit-learn's power, and strategic caching creates a highly performant ML web application suitable for both development and production use.
