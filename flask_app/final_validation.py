#!/usr/bin/env python3
"""
Final validation test to confirm the modernized analysis pipeline
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

print("ğŸš€ Final Pipeline Validation Test")
print("=" * 50)

try:
    # Test 1: Import new function
    print("ğŸ“¦ Testing imports...")
    from model import analyze_company_comprehensive
    print("   âœ… analyze_company_comprehensive imported successfully")
    
    # Test 2: Check function signature and functionality
    print("\nğŸ§ª Testing function execution...")
    test_data = {
        'company_name': 'DealScout Test Inc',
        'industry': 'SaaS',
        'location': 'San Francisco',
        'funding_round': 'Series A',
        'funding_amount_usd': 2500000,
        'valuation_usd': 15000000,
        'team_size': 12,
        'years_since_founding': 1.8,
        'revenue_usd': 250000,
        'num_investors': 2,
        'competition_level': 6,
        'market_size_billion_usd': 8.5,
    }
    
    result = analyze_company_comprehensive(test_data)
    print("   âœ… Function executed without errors")
    
    # Test 3: Validate all required output fields
    print("\nğŸ“‹ Validating output structure...")
    expected_fields = [
        'company_name', 'attractiveness_score', 'success_probability', 
        'predicted_funding', 'recommendation', 'insights', 
        'investment_commentary', 'risk_level', 'investment_tier',
        'market_score', 'team_score', 'financial_score', 'growth_score'
    ]
    
    missing_fields = [field for field in expected_fields if field not in result]
    if missing_fields:
        print(f"   âŒ Missing fields: {missing_fields}")
    else:
        print("   âœ… All required fields present")
    
    # Test 4: Validate investment commentary integration
    print("\nğŸ’¬ Testing investment commentary...")
    commentary = result.get('investment_commentary', [])
    if isinstance(commentary, list) and len(commentary) > 0:
        print(f"   âœ… Commentary generated: {len(commentary)} insights")
        print(f"   ğŸ“ Sample insight: {commentary[0]}")
        
        # Check for diverse commentary types
        commentary_text = ' '.join(commentary)
        has_market = any(word in commentary_text.lower() for word in ['market', 'industry', 'competition'])
        has_financial = any(word in commentary_text.lower() for word in ['revenue', 'funding', 'financial'])
        has_team = any(word in commentary_text.lower() for word in ['team', 'leadership', 'experience'])
        has_growth = any(word in commentary_text.lower() for word in ['growth', 'potential', 'expansion'])
        
        coverage_areas = sum([has_market, has_financial, has_team, has_growth])
        print(f"   ğŸ“Š Commentary covers {coverage_areas}/4 key areas (market, financial, team, growth)")
        
        if coverage_areas >= 3:
            print("   âœ… Comprehensive investment commentary generated")
        else:
            print("   âš ï¸ Commentary could be more comprehensive")
    else:
        print("   âŒ No investment commentary generated")
    
    # Test 5: Validate score ranges
    print("\nğŸ¯ Testing score validity...")
    score = result.get('attractiveness_score', 0)
    probability = result.get('success_probability', 0)
    
    score_valid = 0 <= score <= 100
    prob_valid = 0 <= probability <= 1
    
    print(f"   ğŸ“ˆ Attractiveness Score: {score:.1f}% {'âœ…' if score_valid else 'âŒ'}")
    print(f"   ğŸ¯ Success Probability: {probability:.1%} {'âœ…' if prob_valid else 'âŒ'}")
    print(f"   â­ Recommendation: {result.get('recommendation', 'N/A')}")
    print(f"   ğŸ† Investment Tier: {result.get('investment_tier', 'N/A')}")
    print(f"   âš ï¸ Risk Level: {result.get('risk_level', 'N/A')}")
    
    # Test 6: Validate component scores
    print("\nğŸ“Š Component Score Breakdown:")
    components = ['market_score', 'team_score', 'financial_score', 'growth_score']
    all_components_valid = True
    
    for component in components:
        comp_score = result.get(component, 0)
        comp_valid = 0 <= comp_score <= 100
        all_components_valid = all_components_valid and comp_valid
        print(f"   {component.replace('_', ' ').title()}: {comp_score:.1f}/100 {'âœ…' if comp_valid else 'âŒ'}")
    
    print(f"\nğŸ PIPELINE VALIDATION RESULTS:")
    print(f"   âœ… Function Import: PASSED")
    print(f"   âœ… Function Execution: PASSED")
    print(f"   {'âœ…' if not missing_fields else 'âŒ'} Output Structure: {'PASSED' if not missing_fields else 'FAILED'}")
    print(f"   {'âœ…' if len(commentary) > 0 else 'âŒ'} Investment Commentary: {'PASSED' if len(commentary) > 0 else 'FAILED'}")
    print(f"   {'âœ…' if score_valid and prob_valid else 'âŒ'} Score Validity: {'PASSED' if score_valid and prob_valid else 'FAILED'}")
    print(f"   {'âœ…' if all_components_valid else 'âŒ'} Component Scores: {'PASSED' if all_components_valid else 'FAILED'}")
    
    overall_success = (not missing_fields and len(commentary) > 0 and 
                      score_valid and prob_valid and all_components_valid)
    
    print(f"\nğŸŠ OVERALL RESULT: {'âœ… SUCCESS - Pipeline fully modernized!' if overall_success else 'âŒ Issues detected'}")
    
    if overall_success:
        print("\nğŸ“‹ MODERNIZATION COMPLETE:")
        print("   â€¢ Old evaluate_startup_deal function removed")
        print("   â€¢ New analyze_company_comprehensive function integrated")
        print("   â€¢ Investment commentary directly included in analysis")
        print("   â€¢ All Flask API endpoints updated")
        print("   â€¢ Comprehensive scoring and insights maintained")
    
except Exception as e:
    print(f"âŒ Critical error during validation: {e}")
    import traceback
    traceback.print_exc()
    print("\nğŸ”§ Pipeline needs debugging before completion")

print("\n" + "=" * 50)
print("ğŸ Validation test complete!")